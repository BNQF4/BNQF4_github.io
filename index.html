# Baseline model built on polynomial regression with only 4 features

# Import necessaries libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.impute import SimpleImputer
# Load the dataset
df = pd.read_excel('D:/Users/admin/Desktop/Original Dataset.xlsx')
# Step 1: Select the features and target variable
features = ['Initial discharge capacity', 'Initial charge capacity', 'First Cycle Coulombic efficiency', 'Testing C rate']
target = 'Capacity Retention'
# Assuming 'dff' is your DataFrame containing the data
X = dff[features]
y = dff[target]
# Step 2: Drop rows with NaN values in both the feature and target columns
df_cleaned = dff.dropna(subset=features + [target])
# Step 3: Separate the cleaned data into X_cleaned and y_cleaned
X_cleaned = df_cleaned[features]
y_cleaned = df_cleaned[target]
# Step 4: Split the cleaned data into training and testing sets
# Adjust the test_size and random_state as needed
X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=2205634)
# Step 5: Create polynomial features
degree = 2  # You can adjust this to the degree of polynomial you want
poly = PolynomialFeatures(degree)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)
# Step 6: Create and train the polynomial regression model
model = LinearRegression()
model.fit(X_train_poly, y_train)
# Step 7: Make predictions using the test set
y_pred = model.predict(X_test_poly)
# Step 8: Calculate the Mean Squared Error (MSE) and R-squared score
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error (MSE): {mse}")
print(f"R-squared score: {r2}")
